{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### The reference is https://www.kaggle.com/deinforcement/top-1-predict-future-sales-features-lightgbm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gc\r\n",
    "import itertools\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def reduce_mem_usage(df, silent=True, allow_categorical=True, float_dtype=\"float32\"):\r\n",
    "    \"\"\" \r\n",
    "    Iterates through all the columns of a dataframe and downcasts the data type\r\n",
    "     to reduce memory usage. Can also factorize categorical columns to integer dtype.\r\n",
    "    \"\"\"\r\n",
    "    def _downcast_numeric(series, allow_categorical=allow_categorical):\r\n",
    "        \"\"\"\r\n",
    "        Downcast a numeric series into either the smallest possible int dtype or a specified float dtype.\r\n",
    "        \"\"\"\r\n",
    "        if pd.api.types.is_sparse(series.dtype) is True:\r\n",
    "            return series\r\n",
    "        elif pd.api.types.is_numeric_dtype(series.dtype) is False:\r\n",
    "            if pd.api.types.is_datetime64_any_dtype(series.dtype):\r\n",
    "                return series\r\n",
    "            else:\r\n",
    "                if allow_categorical:\r\n",
    "                    return series\r\n",
    "                else:\r\n",
    "                    codes, uniques = series.factorize()\r\n",
    "                    series = pd.Series(data=codes, index=series.index)\r\n",
    "                    series = _downcast_numeric(series)\r\n",
    "                    return series\r\n",
    "        else:\r\n",
    "            series = pd.to_numeric(series, downcast=\"integer\")\r\n",
    "        if pd.api.types.is_float_dtype(series.dtype):\r\n",
    "            series = series.astype(float_dtype)\r\n",
    "        return series\r\n",
    "\r\n",
    "    if silent is False:\r\n",
    "        start_mem = np.sum(df.memory_usage()) / 1024 ** 2\r\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\r\n",
    "    if df.ndim == 1:\r\n",
    "        df = _downcast_numeric(df)\r\n",
    "    else:\r\n",
    "        for col in df.columns:\r\n",
    "            df.loc[:, col] = _downcast_numeric(df.loc[:,col])\r\n",
    "    if silent is False:\r\n",
    "        end_mem = np.sum(df.memory_usage()) / 1024 ** 2\r\n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\r\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def shrink_mem_new_cols(matrix, oldcols=None, allow_categorical=False):\r\n",
    "    # Calls reduce_mem_usage on columns which have not yet been optimized\r\n",
    "    if oldcols is not None:\r\n",
    "        newcols = matrix.columns.difference(oldcols)\r\n",
    "    else:\r\n",
    "        newcols = matrix.columns\r\n",
    "    matrix.loc[:,newcols] = reduce_mem_usage(matrix.loc[:,newcols], allow_categorical=allow_categorical)\r\n",
    "    oldcols = matrix.columns  # This is used to track which columns have already been downcast\r\n",
    "    return matrix, oldcols\r\n",
    "\r\n",
    "\r\n",
    "def list_if_not(s, dtype=str):\r\n",
    "    # Puts a variable in a list if it is not already a list\r\n",
    "    if type(s) not in (dtype, list):\r\n",
    "        raise TypeError\r\n",
    "    if (s != \"\") & (type(s) is not list):\r\n",
    "        s = [s]\r\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import os\r\n",
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RT009223\\\\Github\\\\Projects\\\\SideProject\\\\05_Predict_Future_Sales'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "items = pd.read_csv(\"./data/items.csv\")\r\n",
    "shops = pd.read_csv(\"./data/shops.csv\")\r\n",
    "train = pd.read_csv(\"./data/sales_train.csv\")\r\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Merge some duplicate shops\r\n",
    "train[\"shop_id\"] = train[\"shop_id\"].replace({0: 57, 1: 58, 11: 10, 40: 39})\r\n",
    "# Keep only shops that are in the test set\r\n",
    "train = train.loc[train.shop_id.isin(test[\"shop_id\"].unique()), :]\r\n",
    "# Drop training items with extreme or negative prices or sales counts\r\n",
    "train = train[(train[\"item_price\"] > 0) & (train[\"item_price\"] < 50000)]\r\n",
    "train = train[(train[\"item_cnt_day\"] > 0) & (train[\"item_cnt_day\"] < 1000)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def create_testlike_train(sales_train, test=None):\r\n",
    "    indexlist = []\r\n",
    "    for i in sales_train.date_block_num.unique():\r\n",
    "        x = itertools.product(\r\n",
    "            [i],\r\n",
    "            sales_train.loc[sales_train.date_block_num == i].shop_id.unique(),\r\n",
    "            sales_train.loc[sales_train.date_block_num == i].item_id.unique(),\r\n",
    "        )\r\n",
    "        indexlist.append(np.array(list(x)))\r\n",
    "    df = pd.DataFrame(\r\n",
    "        data=np.concatenate(indexlist, axis=0),\r\n",
    "        columns=[\"date_block_num\", \"shop_id\", \"item_id\"],\r\n",
    "    )\r\n",
    "\r\n",
    "    # Add revenue column to sales_train\r\n",
    "    sales_train[\"item_revenue_day\"] = sales_train[\"item_price\"] * sales_train[\"item_cnt_day\"]\r\n",
    "    # Aggregate item_id / shop_id item_cnts and revenue at the month level\r\n",
    "    sales_train_grouped = sales_train.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg(\r\n",
    "        item_cnt_month=pd.NamedAgg(column=\"item_cnt_day\", aggfunc=\"sum\"),\r\n",
    "        item_revenue_month=pd.NamedAgg(column=\"item_revenue_day\", aggfunc=\"sum\"),\r\n",
    "    )\r\n",
    "\r\n",
    "    # Merge the grouped data with the index\r\n",
    "    df = df.merge(\r\n",
    "        sales_train_grouped, how=\"left\", on=[\"date_block_num\", \"shop_id\", \"item_id\"],\r\n",
    "    )\r\n",
    "\r\n",
    "    if test is not None:\r\n",
    "        test[\"date_block_num\"] = 34\r\n",
    "        test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\r\n",
    "        test[\"shop_id\"] = test.shop_id.astype(np.int8)\r\n",
    "        test[\"item_id\"] = test.item_id.astype(np.int16)\r\n",
    "        test = test.drop(columns=\"ID\")\r\n",
    "\r\n",
    "        df = pd.concat([df, test[[\"date_block_num\", \"shop_id\", \"item_id\"]]])\r\n",
    "\r\n",
    "    # Fill empty item_cnt entries with 0\r\n",
    "    df.item_cnt_month = df.item_cnt_month.fillna(0)\r\n",
    "    df.item_revenue_month = df.item_revenue_month.fillna(0)\r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "matrix = create_testlike_train(train, test)\r\n",
    "del(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "matrix = reduce_mem_usage(matrix, silent=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 405.44 MB\n",
      "Memory usage after optimization is: 152.04 MB\n",
      "Decreased by 62.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "items.query(\"item_id>3564\").head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              item_name  item_id  \\\n",
       "3565                      Fuse [PS3, английская версия]     3565   \n",
       "3566                 Fuse [Xbox 360, английская версия]     3566   \n",
       "3567  G Data Internet Security 2013 (1ПК / 1 год) (G...     3567   \n",
       "3568  G Data Internet Security 2013 (3ПК / 1 год) (G...     3568   \n",
       "3569                      GABIN  The Best Of Gabin  2CD     3569   \n",
       "\n",
       "      item_category_id  \n",
       "3565                19  \n",
       "3566                23  \n",
       "3567                76  \n",
       "3568                76  \n",
       "3569                55  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>Fuse [PS3, английская версия]</td>\n",
       "      <td>3565</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>Fuse [Xbox 360, английская версия]</td>\n",
       "      <td>3566</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>G Data Internet Security 2013 (1ПК / 1 год) (G...</td>\n",
       "      <td>3567</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>G Data Internet Security 2013 (3ПК / 1 год) (G...</td>\n",
       "      <td>3568</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>GABIN  The Best Of Gabin  2CD</td>\n",
       "      <td>3569</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "import re\r\n",
    "\r\n",
    "from fuzzywuzzy import fuzz\r\n",
    "\r\n",
    "def add_item_name_groups(matrix, train, items, sim_thresh, feature_name=\"item_name_group\"):\r\n",
    "    def partialmatchgroups(items, sim_thresh=sim_thresh):\r\n",
    "        def strip_brackets(string):\r\n",
    "            string = re.sub(r\"\\(.*?\\)\", \"\", string)\r\n",
    "            string = re.sub(r\"\\[.*?\\]\", \"\", string)\r\n",
    "            return string\r\n",
    "\r\n",
    "        items = items.copy()\r\n",
    "        items[\"nc\"] = items.item_name.apply(strip_brackets)\r\n",
    "        items[\"ncnext\"] = np.concatenate((items[\"nc\"].to_numpy()[1:], np.array([\"\"])))\r\n",
    "\r\n",
    "        def partialcompare(s):\r\n",
    "            return fuzz.partial_ratio(s[\"nc\"], s[\"ncnext\"])\r\n",
    "\r\n",
    "        items[\"partialmatch\"] = items.apply(partialcompare, axis=1)\r\n",
    "        # Assign groups\r\n",
    "        grp = 0\r\n",
    "        for i in range(items.shape[0]):\r\n",
    "            items.loc[i, \"partialmatchgroup\"] = grp\r\n",
    "            if items.loc[i, \"partialmatch\"] < sim_thresh:\r\n",
    "                grp += 1\r\n",
    "        items = items.drop(columns=[\"nc\", \"ncnext\", \"partialmatch\"])\r\n",
    "        return items\r\n",
    "\r\n",
    "    items = partialmatchgroups(items)\r\n",
    "    items = items.rename(columns={\"partialmatchgroup\": feature_name})\r\n",
    "    items = items.drop(columns=\"partialmatchgroup\", errors=\"ignore\")\r\n",
    "\r\n",
    "    items[feature_name] = items[feature_name].apply(str)\r\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\r\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\r\n",
    "    train = train.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\r\n",
    "    return matrix, train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "matrix, train = add_item_name_groups(matrix, train, items, 65)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "\r\n",
    "def add_first_word_features(matrix, items=items, feature_name=\"artist_name_or_first_word\"):\r\n",
    "    # This extracts artist names for music categories and adds them as a feature.\r\n",
    "    def extract_artist(st):\r\n",
    "        st = st.strip()\r\n",
    "        if st.startswith(\"V/A\"):\r\n",
    "            artist = \"V/A\"\r\n",
    "        elif st.startswith(\"СБ\"):\r\n",
    "            artist = \"СБ\"\r\n",
    "        else:\r\n",
    "            # Retrieves artist names using the double space or all uppercase pattern\r\n",
    "            mus_artist_dubspace = re.compile(r\".{2,}?(?=\\s{2,})\")\r\n",
    "            match_dubspace = mus_artist_dubspace.match(st)\r\n",
    "            mus_artist_capsonly = re.compile(r\"^([^a-zа-я]+\\s)+\")\r\n",
    "            match_capsonly = mus_artist_capsonly.match(st)\r\n",
    "            candidates = [match_dubspace, match_capsonly]\r\n",
    "            candidates = [m[0] for m in candidates if m is not None]\r\n",
    "            # Sometimes one of the patterns catches some extra words so choose the shortest one\r\n",
    "            if len(candidates):\r\n",
    "                artist = min(candidates, key=len)\r\n",
    "            else:\r\n",
    "                # If neither of the previous patterns found something, use the dot-space pattern\r\n",
    "                mus_artist_dotspace = re.compile(r\".{2,}?(?=\\.\\s)\")\r\n",
    "                match = mus_artist_dotspace.match(st)\r\n",
    "                if match:\r\n",
    "                    artist = match[0]\r\n",
    "                else:\r\n",
    "                    artist = \"\"\r\n",
    "        artist = artist.upper()\r\n",
    "        artist = re.sub(r\"[^A-ZА-Я ]||\\bTHE\\b\", \"\", artist)\r\n",
    "        artist = re.sub(r\"\\s{2,}\", \" \", artist)\r\n",
    "        artist = artist.strip()\r\n",
    "        return artist\r\n",
    "\r\n",
    "    items = items.copy()\r\n",
    "    all_stopwords = stopwords.words(\"russian\")\r\n",
    "    all_stopwords = all_stopwords + stopwords.words(\"english\")\r\n",
    "\r\n",
    "    def first_word(string):\r\n",
    "        # This cleans the string of special characters, excess spaces and stopwords then extracts the first word\r\n",
    "        string = re.sub(r\"[^\\w\\s]\", \"\", string)\r\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\r\n",
    "        tokens = string.lower().split()\r\n",
    "        tokens = [t for t in tokens if t not in all_stopwords]\r\n",
    "        token = tokens[0] if len(tokens) > 0 else \"\"\r\n",
    "        return token\r\n",
    "\r\n",
    "    music_categories = [55, 56, 57, 58, 59, 60]\r\n",
    "    items.loc[items.item_category_id.isin(music_categories), feature_name] = items.loc[\r\n",
    "        items.item_category_id.isin(music_categories), \"item_name\"\r\n",
    "    ].apply(extract_artist)\r\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other music\"\r\n",
    "    items.loc[~items.item_category_id.isin(music_categories), feature_name] = items.loc[\r\n",
    "        ~items.item_category_id.isin(music_categories), \"item_name\"\r\n",
    "    ].apply(first_word)\r\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other non-music\"\r\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\r\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\",)\r\n",
    "    return matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "matrix = add_first_word_features(\r\n",
    "    matrix, items=items, feature_name=\"artist_name_or_first_word\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}